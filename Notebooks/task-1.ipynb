{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T17:50:39.925888Z",
     "iopub.status.busy": "2025-12-20T17:50:39.925644Z",
     "iopub.status.idle": "2025-12-20T17:50:39.929990Z",
     "shell.execute_reply": "2025-12-20T17:50:39.929459Z",
     "shell.execute_reply.started": "2025-12-20T17:50:39.925864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, glob, ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import ViltProcessor, ViltModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T17:50:39.930906Z",
     "iopub.status.busy": "2025-12-20T17:50:39.930692Z",
     "iopub.status.idle": "2025-12-20T17:50:42.694303Z",
     "shell.execute_reply": "2025-12-20T17:50:42.693362Z",
     "shell.execute_reply.started": "2025-12-20T17:50:39.930884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 0) Load item_feature (sans embeddings)\n",
    "# -----------------------------\n",
    "item_feat = pd.read_parquet(\n",
    "    \"/kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/item_feature.parquet\"\n",
    ")\n",
    "\n",
    "# On garde uniquement les colonnes utiles pour le texte (et item_id)\n",
    "keep_cols = [\"item_id\", \"item_title\", \"item_tags\", \"likes_level\", \"views_level\"]\n",
    "item_feat_small = item_feat[keep_cols].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T17:50:42.695756Z",
     "iopub.status.busy": "2025-12-20T17:50:42.695338Z",
     "iopub.status.idle": "2025-12-20T17:50:44.282500Z",
     "shell.execute_reply": "2025-12-20T17:50:44.281677Z",
     "shell.execute_reply.started": "2025-12-20T17:50:42.695724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Construire le texte brut à partir de item_title + item_tags (+ optionnel likes/views)\n",
    "# -----------------------------\n",
    "def parse_tags(x):\n",
    "    \"\"\"Retourne une liste de tags (strings) depuis list/array/string.\"\"\"\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        return [str(t).strip() for t in x if str(t).strip()]\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if not s:\n",
    "            return []\n",
    "        # Cas: string qui ressemble à une liste python \"['a','b']\"\n",
    "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "            try:\n",
    "                obj = ast.literal_eval(s)\n",
    "                if isinstance(obj, (list, tuple)):\n",
    "                    return [str(t).strip() for t in obj if str(t).strip()]\n",
    "            except Exception:\n",
    "                pass\n",
    "        # Cas: tags séparés par , ou |\n",
    "        if \"|\" in s:\n",
    "            return [t.strip() for t in s.split(\"|\") if t.strip()]\n",
    "        if \",\" in s:\n",
    "            return [t.strip() for t in s.split(\",\") if t.strip()]\n",
    "        # Sinon un seul tag\n",
    "        return [s]\n",
    "    return [str(x).strip()]\n",
    "\n",
    "def build_text(row, use_levels=True):\n",
    "    title = str(row[\"item_title\"]).strip() if pd.notna(row[\"item_title\"]) else \"\"\n",
    "    tags = parse_tags(row[\"item_tags\"])\n",
    "\n",
    "    parts = []\n",
    "    if title:\n",
    "        parts.append(title)\n",
    "    if tags:\n",
    "        parts.append(\"tags: \" + \", \".join(tags))\n",
    "\n",
    "    # Optionnel: ajouter likes/views comme texte (ça peut aider ViLT)\n",
    "    if use_levels:\n",
    "        if pd.notna(row[\"likes_level\"]):\n",
    "            parts.append(f\"likes_level: {row['likes_level']}\")\n",
    "        if pd.notna(row[\"views_level\"]):\n",
    "            parts.append(f\"views_level: {row['views_level']}\")\n",
    "\n",
    "    return \" | \".join(parts) if parts else \"\"\n",
    "\n",
    "texts = item_feat_small.apply(lambda r: build_text(r, use_levels=True), axis=1).tolist()\n",
    "item_ids = item_feat_small[\"item_id\"].astype(int).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T17:50:44.283703Z",
     "iopub.status.busy": "2025-12-20T17:50:44.283439Z",
     "iopub.status.idle": "2025-12-20T18:01:42.066349Z",
     "shell.execute_reply": "2025-12-20T18:01:42.065703Z",
     "shell.execute_reply.started": "2025-12-20T17:50:44.283667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) Récupérer les images brutes (sans img_emb_CLIPRN50)\n",
    "# -----------------------------\n",
    "IMAGES_DIR = \"/kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/item_images\"  # adapte si besoin\n",
    "\n",
    "def find_image_path(item_id: int):\n",
    "    # essaye les extensions courantes\n",
    "    for ext in (\"jpg\", \"png\", \"jpeg\", \"webp\"):\n",
    "        p = os.path.join(IMAGES_DIR, f\"{item_id}.{ext}\")\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    # fallback glob\n",
    "    cand = glob.glob(os.path.join(IMAGES_DIR, f\"{item_id}.*\"))\n",
    "    return cand[0] if cand else None\n",
    "\n",
    "img_paths = [find_image_path(i) for i in item_ids]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T18:01:42.067819Z",
     "iopub.status.busy": "2025-12-20T18:01:42.067487Z",
     "iopub.status.idle": "2025-12-20T18:37:04.529357Z",
     "shell.execute_reply": "2025-12-20T18:37:04.528440Z",
     "shell.execute_reply.started": "2025-12-20T18:01:42.067783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) ViLT (image brute + texte brut) -> embedding fusionné\n",
    "# -----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"dandelin/vilt-b32-mlm\"\n",
    "processor = ViltProcessor.from_pretrained(model_id)\n",
    "model = ViltModel.from_pretrained(model_id).to(device).eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def vilt_cls_batch(images_pil, texts_batch):\n",
    "    inputs = processor(\n",
    "        images=images_pil,\n",
    "        text=texts_batch,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "    out = model(**inputs)\n",
    "    cls = out.last_hidden_state[:, 0, :]      # (B, hidden)\n",
    "    cls = F.normalize(cls, p=2, dim=-1)\n",
    "    return cls.cpu().numpy()\n",
    "\n",
    "BATCH = 16  # augmente si GPU OK\n",
    "vecs = []\n",
    "\n",
    "for s in range(0, len(item_ids), BATCH):\n",
    "    batch_texts = texts[s:s+BATCH]\n",
    "    batch_paths = img_paths[s:s+BATCH]\n",
    "\n",
    "    images = []\n",
    "    for p in batch_paths:\n",
    "        if p is None:\n",
    "            images.append(Image.fromarray(np.zeros((224,224,3), dtype=np.uint8)).convert(\"RGB\"))\n",
    "        else:\n",
    "            images.append(Image.open(p).convert(\"RGB\"))\n",
    "\n",
    "    vecs.append(vilt_cls_batch(images, batch_texts))\n",
    "\n",
    "X = np.vstack(vecs)  # (N, hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T18:37:04.530994Z",
     "iopub.status.busy": "2025-12-20T18:37:04.530619Z",
     "iopub.status.idle": "2025-12-20T18:37:05.306571Z",
     "shell.execute_reply": "2025-12-20T18:37:05.305931Z",
     "shell.execute_reply.started": "2025-12-20T18:37:04.530962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) PCA -> 128 dims + normalisation\n",
    "# -----------------------------\n",
    "pca = PCA(n_components=128, random_state=42)\n",
    "X128 = pca.fit_transform(X).astype(np.float32)\n",
    "X128 = X128 / (np.linalg.norm(X128, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "print(\"fin\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T18:37:05.307578Z",
     "iopub.status.busy": "2025-12-20T18:37:05.307319Z",
     "iopub.status.idle": "2025-12-20T18:37:07.004787Z",
     "shell.execute_reply": "2025-12-20T18:37:07.003845Z",
     "shell.execute_reply.started": "2025-12-20T18:37:05.307551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- chemins ---\n",
    "ITEM_INFO_PATH = \"/kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/MicroLens_1M_x1/item_info.parquet\"\n",
    "OUT_PATH = \"./item_info_updated_emb.parquet\"\n",
    "\n",
    "# --- données déjà calculées chez toi ---\n",
    "# item_ids : liste des item_id dans le même ordre que X128\n",
    "# X128 : numpy array (N, 128) float32\n",
    "# ex: item_ids = item_feat_small[\"item_id\"].astype(int).tolist()\n",
    "\n",
    "col_name = \"item_emb_d128\"   # nom exact de la colonne à modifier\n",
    "\n",
    "# 1) lire item_info\n",
    "item_info = pd.read_parquet(ITEM_INFO_PATH)\n",
    "\n",
    "# 2) vérifier la colonne existe\n",
    "if col_name not in item_info.columns:\n",
    "    raise ValueError(f\"La colonne '{col_name}' n'existe pas dans item_info. Colonnes: {list(item_info.columns)}\")\n",
    "\n",
    "# 3) construire un mapping item_id -> embedding(128)\n",
    "id_to_vec = {int(i): X128[k].astype(np.float32).tolist() for k, i in enumerate(item_ids)}\n",
    "\n",
    "# 4) remplacer le contenu de la colonne, ligne par ligne\n",
    "item_info[\"item_id\"] = item_info[\"item_id\"].astype(int)\n",
    "item_info[col_name] = item_info[\"item_id\"].map(lambda x: id_to_vec.get(x, [0.0]*128))  # vecteur 0 si manquant\n",
    "\n",
    "# 5) vérifier qu’on n’a plus de NaN\n",
    "missing = item_info[col_name].isna().sum()\n",
    "print(f\"Nombre d'embeddings manquants remplacés par 0 : {missing}\")\n",
    "\n",
    "# 6) sauvegarder\n",
    "item_info.to_parquet(OUT_PATH, index=False)\n",
    "print(\"Saved:\", OUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7878862,
     "sourceId": 12486024,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
